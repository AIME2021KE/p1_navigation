{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the first project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893).\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing some necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description of the implementation approach is provided below past the section where the random implementation is commented out.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "#get_ipython().system('python -m pip install pyvirtualdisplay')\n",
    "#from pyvirtualdisplay import Display\n",
    "#display = Display(visible=0, size=(1400, 900))\n",
    "#display.start()\n",
    "\n",
    "is_ipython = 'inline' in plt.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Banana.app\"`\n",
    "- **Windows** (x86): `\"path/to/Banana_Windows_x86/Banana.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Banana_Windows_x86_64/Banana.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Banana_Linux/Banana.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Banana_Linux/Banana.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Banana_Linux_NoVis/Banana.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Banana_Linux_NoVis/Banana.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Banana.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Banana.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "#env = UnityEnvironment(file_name=\"...\")\n",
    "# NOTE: seem to need to specify worker_id from time to time...\n",
    "#NOTE 2/18/2022: we sometimes get errors and have to switch the worker_id; values of 1 and 2 seeme to cover most problems\n",
    "env = UnityEnvironment(\n",
    "    file_name=\"./Banana.exe\",worker_id=1)\n",
    "#env = UnityEnvironment(file_name=\"./Banana.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , ,  ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_academy_name', '_brain_names', '_brains', '_buffer_size', '_close', '_curriculum', '_external_brain_names', '_flatten', '_generate_reset_input', '_generate_step_input', '_get_state', '_global_done', '_loaded', '_log_path', '_n_agents', '_num_brains', '_num_external_brains', '_process_pixels', '_resetParameters', '_unity_version', '_version_', 'academy_name', 'brain_names', 'brains', 'close', 'communicator', 'curriculum', 'executable_launcher', 'external_brain_names', 'get_communicator', 'global_done', 'logfile_path', 'number_brains', 'number_external_brains', 'port', 'proc1', 'reset', 'send_academy_parameters', 'step', 'wrap_unity_input']\n"
     ]
    }
   ],
   "source": [
    "print(env,dir(env))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'brain_name', 'camera_resolutions', 'num_stacked_vector_observations', 'number_visual_observations', 'vector_action_descriptions', 'vector_action_space_size', 'vector_action_space_type', 'vector_observation_space_size', 'vector_observation_space_type']\n"
     ]
    }
   ],
   "source": [
    "print(brain)\n",
    "print(dir(brain))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "The simulation contains a single agent that navigates a large environment.  At each time step, it has four actions at its disposal:\n",
    "- `0` - walk forward \n",
    "- `1` - walk backward\n",
    "- `2` - turn left\n",
    "- `3` - turn right\n",
    "\n",
    "The state space has `37` dimensions and contains the agent's velocity, along with ray-based perception of objects around agent's forward direction.  A reward of `+1` is provided for collecting a yellow banana, and a reward of `-1` is provided for collecting a blue banana. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Number of actions: 4\n",
      "States look like: [1.         0.         0.         0.         0.84408134 0.\n",
      " 0.         1.         0.         0.0748472  0.         1.\n",
      " 0.         0.         0.25755    1.         0.         0.\n",
      " 0.         0.74177343 0.         1.         0.         0.\n",
      " 0.25854847 0.         0.         1.         0.         0.09355672\n",
      " 0.         1.         0.         0.         0.31969345 0.\n",
      " 0.        ]\n",
      "States have length: 37\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents in the environment\n",
    "print('Number of agents:', len(env_info.agents))\n",
    "\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "state = env_info.vector_observations[0]\n",
    "print('States look like:', state)\n",
    "state_size = len(state)\n",
    "print('States have length:', state_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unityagents.brain.BrainInfo object at 0x000001AF4F6D47B8> ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'agents', 'local_done', 'max_reached', 'memories', 'previous_text_actions', 'previous_vector_actions', 'rewards', 'text_observations', 'vector_observations', 'visual_observations']\n"
     ]
    }
   ],
   "source": [
    "print(env_info,dir(env_info))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BananaBrain': <unityagents.brain.BrainParameters object at 0x000001AF4F6D4BA8>}\n"
     ]
    }
   ],
   "source": [
    "print(env.brains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['']\n",
      "[[0.]]\n",
      "['']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(env_info.memories)\n",
    "print(env_info.previous_text_actions)\n",
    "print(env_info.previous_vector_actions)\n",
    "print(env_info.text_observations)\n",
    "print(env_info.visual_observations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action (uniformly) at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agent is able to use its experience to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE 2/18/2022 KAE: this was in the project previously but we modified it slightly to go through n_episodes (currently 10) \n",
    "# given the above statement we commented this out instead of leaving in as a reference.\n",
    "#n_episodes = 10\n",
    "#for i_episode in range(1, n_episodes+1):\n",
    "#    print('i: ',i_episode)\n",
    "#    env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "#    state = env_info.vector_observations[0]            # get the current state\n",
    "#    score = 0                                          # initialize the score\n",
    "#    while True:\n",
    "#        action = np.random.randint(action_size)        # select an action\n",
    "#        env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "#        next_state = env_info.vector_observations[0]   # get the next state\n",
    "#        reward = env_info.rewards[0]                   # get the reward\n",
    "#        done = env_info.local_done[0]                  # see if episode has finished\n",
    "#        score += reward                                # update the score\n",
    "#        state = next_state                             # roll over the state to next time step\n",
    "#        if done:                                       # exit loop if episode finished\n",
    "#            print('i, final score: ',i_episode, score)\n",
    "#           break\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE this seems to end the session COMPLETELY so moving it to bottom of page....\n",
    "#env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRELIMINARY NOTES:\n",
    "Ran the random actions provided section of code (now commented out) above (for 10 episodes) and get a score of 0.0. We assume this is normal as the video fails to provide this key element but it \"makes sense\"\n",
    "\n",
    "Our expectation based in the instructions is to start with our DQN model we used prior and to adjust to fit into this different (Unity) paradym for starters and to meet the performance requirement as needed. We didn't find this necessary however.\n",
    "\n",
    "We started with just importing the model and agent from DQN as before. Locally we've renamed the python files dqn_model.py and dqn_agent.py. We found this model to work adequately and so didn't try anything else, but will see about implementing some of the other techniques as well. \n",
    "\n",
    "## APPROACH\n",
    "We started with the default (intial) values for the DQN internal or hyperparameters, expecting to make further refinements and network adjustments as needed to meet the requirements, but none were needed because the defaults trained quickly (< 500 episodes). \n",
    "\n",
    "The two included python files are dqn_model.py, which contains the QNetwork implementation (only seen by the agent) from DQN, and dqn_agent.py, which contains the Agent class as well as a supporting ReplayBuffer class to store the experiences in tuples for use by the Qnetworks.\n",
    "\n",
    "### QNetwork \n",
    "Is composed of 3 fully connected layers with two NN internal sizes (defaults: fc1_size=64 and fc2_size=64) using RELU activation functions along with an initial state_size and a final action_size to map into the bananas input (state) and output (action) environment. The Qnetwork has an __init__ function to be invoked on class creation and the forward method using the NN's to convert the current state into an action.\n",
    "\n",
    "### Agent: \n",
    "The initial agent solution used in the DQN mini project was used as-is with the following Hyperparamters:\n",
    "\n",
    "Buffer size: 100,000\n",
    "\n",
    "batch size: 64\n",
    "\n",
    "gamma: 0.99 # discount factor for subsequent rewards\n",
    "\n",
    "tau: 1e-3, # soft update of the target parameters\n",
    "\n",
    "LR: 5e-4, # learning rate\n",
    "\n",
    "UPDATE_EVERY: 4, how often to update the network\n",
    "\n",
    "The Agent class itself is composed of an \"__init__\" fuction for construction, which creates the two qnetworks, one that is local and one that is the target network, along with the optimizer and memory buffer from the ReplayBuffer class to store experiences. \n",
    "\n",
    "The Agent step method adds the current experience into the memory buffer, and every UPDATE_EVERY steps stores the experience into memory and exectutes the learn fucntion.\n",
    "\n",
    "The Agent act method returns actions for a given state given current policy. It does this by evaluating (eval) the local qnetwork, get new actions from the local qnetwork, train the local network, and finally select actions either randomly (if a random toss is bigger than the hyperparameter eps, which for our setup has a start (max), end(min) and a decay (multiplier to determine new eps value) to allow it to start pretty randomly but (slowly) select more from the train policy actions.\n",
    "\n",
    "The Agent learn method was the one for which we had to provide the appropriate solutions previously with the DQN mini-project. Here we unpack the tuple experiences into states, actions, rewards, next_states, and dones. The next_states are used in the target (NOT local) qnetwork to get the next target actions. These are then detached from the resulting tensor to make a true copy, access Qtable for the next action, and hence the rewards of the target network. The resulting tensor has to be (carefully) unpacked to get it into the correct form to be used in subsequent calculations. We then get the next action results from the local qnetwork and then determine the MSE loss between the target and local network fits. We then zero_grad the optimizer, propagate the loss backwards through the network, and perform a step in the optimizer. Finally a soft update is performed on the target network, using TAU times the local network parameters and (1-TAU) times the target network parameters to update the target network parameters.\n",
    "\n",
    "As indicated the original DQN agent has a helper class ReplayBuffer, with methods add, to add experiences to the buffer, and sample, to sample experiences from the buffer, and is used extensively in the step method for the Agent class.\n",
    "\n",
    "Originally we expected to look at some of the post-dqn example approaches, especially the dueling networks and the prioritized experience replay. However since these were mainly modifications of the internal workings of the agents and the like. we felt that it was best to first get the baseline DQN running and then see if there are problems about possibly making these modifications. \n",
    "\n",
    "So we start with our original agent and model, which we've imported locally and import the (slightly modified) dqn function for the unity setup. \n",
    "\n",
    "This is then inported in the section below the \n",
    "#### \"connecting with Unity instead of Gym\" ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dqn_agent import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n"
     ]
    }
   ],
   "source": [
    "len_agents = len(env_info.agents)\n",
    "# number of agents in the environment\n",
    "print('Number of agents:', len_agents)\n",
    "#from dqn_agent import Agent\n",
    "agent = Agent(state_size=state_size, action_size=action_size, seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting with Unity instead of Gym\n",
    "There are a few differences between AIGym and Unity; namely how the env is defined and used.\n",
    "\n",
    "We use the dqn function we had before with a few minor tweaks to meet our needs, including a train_mode logical, and the max score threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ORIGINAL DQN function interface: def dqn(agent, env, env_info, n_episodes=2000, max_t=1000, eps_start=1.0, eps_end=0.01, \n",
    "#        eps_decay=0.995, dprint=100):\n",
    "def dqn(agent, env, brain_name, train_mode=True, n_episodes=2000, max_t=1000, eps_start=1.0, eps_end=0.01, \n",
    "        eps_decay=0.995, dprint=100, MAX_SCORE=13.0):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        agent: agent class with embedded model\n",
    "        env: environment class, now from unity\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "    \"\"\"\n",
    "    scores = []                        # list containing scores from each episode\n",
    "    ave_scores = []                    # list containing ave scores from dprint average\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    eps = eps_start                    # initialize epsilon\n",
    "    prev_score = 0\n",
    "    print('before episodes:',str(env))\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=train_mode)[brain_name]\n",
    "        state = env_info.vector_observations[0]            # get the current state\n",
    "        score = 0\n",
    "        for t in range(max_t):\n",
    "            action = agent.act(state, eps)\n",
    "            env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "            \n",
    "            # NOTE: steal the way of getting next_state, reward, done from environment\n",
    "            next_state = env_info.vector_observations[0]   # get the next state\n",
    "            reward = env_info.rewards[0]                   # get the reward\n",
    "            done = env_info.local_done[0]                  # see if episode has finished\n",
    "            # NOTE KAE: we kept this in as this was part of our attempts to test (train_mode=False) but \n",
    "            #  didn't seem to work as well unless train_mode was true (run the agent.step)\n",
    "#            if train_mode:\n",
    "#                agent.step(state, action, reward, next_state, done)\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "    \n",
    "            state = next_state\n",
    "            score += reward\n",
    "            if score > prev_score:\n",
    "                prev_score = score\n",
    "            \n",
    "            if done:\n",
    "                break \n",
    "        scores_window.append(score)       # save most recent score\n",
    "        scores.append(score)              # save most recent score\n",
    "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "        if i_episode % dprint == 0:\n",
    "            ave_score = np.mean(scores_window)\n",
    "            ave_scores.append(ave_score)\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, ave_score))\n",
    "        if (np.mean(scores_window)>= MAX_SCORE):\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
    "            if  train_mode:\n",
    "                torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n",
    "            break\n",
    "    return scores, ave_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before episodes: Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n",
      "Episode 10\tAverage Score: -0.30\n",
      "Episode 20\tAverage Score: -0.15\n",
      "Episode 30\tAverage Score: -0.03\n",
      "Episode 40\tAverage Score: 0.03\n",
      "Episode 50\tAverage Score: 0.00\n",
      "Episode 60\tAverage Score: 0.07\n",
      "Episode 70\tAverage Score: 0.20\n",
      "Episode 80\tAverage Score: 0.33\n",
      "Episode 90\tAverage Score: 0.44\n",
      "Episode 100\tAverage Score: 0.67\n",
      "Episode 110\tAverage Score: 1.04\n",
      "Episode 120\tAverage Score: 1.32\n",
      "Episode 130\tAverage Score: 1.75\n",
      "Episode 140\tAverage Score: 2.09\n",
      "Episode 150\tAverage Score: 2.66\n",
      "Episode 160\tAverage Score: 3.04\n",
      "Episode 170\tAverage Score: 3.60\n",
      "Episode 180\tAverage Score: 3.97\n",
      "Episode 190\tAverage Score: 4.33\n",
      "Episode 200\tAverage Score: 4.55\n",
      "Episode 210\tAverage Score: 4.80\n",
      "Episode 220\tAverage Score: 5.12\n",
      "Episode 230\tAverage Score: 5.45\n",
      "Episode 240\tAverage Score: 5.79\n",
      "Episode 250\tAverage Score: 5.90\n",
      "Episode 260\tAverage Score: 6.31\n",
      "Episode 270\tAverage Score: 6.42\n",
      "Episode 280\tAverage Score: 6.74\n",
      "Episode 290\tAverage Score: 6.88\n",
      "Episode 300\tAverage Score: 7.19\n",
      "Episode 310\tAverage Score: 7.31\n",
      "Episode 320\tAverage Score: 7.65\n",
      "Episode 330\tAverage Score: 7.83\n",
      "Episode 340\tAverage Score: 7.95\n",
      "Episode 350\tAverage Score: 8.55\n",
      "Episode 360\tAverage Score: 8.53\n",
      "Episode 370\tAverage Score: 8.69\n",
      "Episode 380\tAverage Score: 8.76\n",
      "Episode 390\tAverage Score: 9.28\n",
      "Episode 400\tAverage Score: 9.55\n",
      "Episode 410\tAverage Score: 10.04\n",
      "Episode 420\tAverage Score: 10.15\n",
      "Episode 430\tAverage Score: 10.35\n",
      "Episode 440\tAverage Score: 10.58\n",
      "Episode 450\tAverage Score: 10.52\n",
      "Episode 460\tAverage Score: 11.15\n",
      "Episode 470\tAverage Score: 11.61\n",
      "Episode 480\tAverage Score: 12.20\n",
      "Episode 490\tAverage Score: 12.26\n",
      "Episode 500\tAverage Score: 12.48\n",
      "Episode 510\tAverage Score: 12.54\n",
      "Episode 520\tAverage Score: 12.89\n",
      "\n",
      "Environment solved in 428 episodes!\tAverage Score: 13.01\n"
     ]
    }
   ],
   "source": [
    "dprint = 10\n",
    "scores, ave_scores = dqn(agent, env, brain_name, train_mode=True, n_episodes=2000, max_t=1000, eps_start=1.0, \n",
    "             eps_end=0.01, eps_decay=0.995, dprint=dprint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.plot(np.arange(len(ave_scores))*dprint, ave_scores,'r.-')\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before episodes: Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n",
      "Episode 10\tAverage Score: 10.40\n",
      "Episode 20\tAverage Score: 10.85\n",
      "Episode 30\tAverage Score: 11.30\n",
      "Episode 40\tAverage Score: 12.15\n",
      "Episode 50\tAverage Score: 12.46\n",
      "Episode 60\tAverage Score: 12.80\n",
      "\n",
      "Environment solved in -34 episodes!\tAverage Score: 13.02\n"
     ]
    }
   ],
   "source": [
    "agent.qnetwork_local.load_state_dict(torch.load('checkpoint.pth'))\n",
    "agent.qnetwork_local.eval()\n",
    "#env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "\n",
    "#scores = dqn(agent, env, brain_name, train_mode=False, n_episodes=2000, max_t=1000, eps_start=1.0, \n",
    "#             eps_end=0.01, eps_decay=0.995, dprint=100)\n",
    "tscores, tave_scores = dqn(agent, env, brain_name, train_mode=False, n_episodes=2000, max_t=1000, eps_start=0.0, \n",
    "             eps_end=0.00, eps_decay=0.995, dprint=dprint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "528"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(len(tscores))\n",
    "len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possible Future Improvements\n",
    "To me the possible future improvements break into two basic cateogries\n",
    "#### 1) change dqn internals: hyperparameters, architecture, etc but with the same basic structure as before with the intent to decrease the time to get mean (last 100) score of 13 or more\n",
    "\n",
    "#####       a) Increase LR (learning rate) to see if can converge faster  \n",
    "\n",
    "#####       b) Increase Update_Every (how often to update the network) to save a little more information per reward  \n",
    "\n",
    "#####       c) Increase the size of the inner fixed sizes from 64 each to something larger if effective  \n",
    "\n",
    "#####       e) Doesn't seem like increasing the buffer size (100,000) or batch size (64) would help much; nor changing the discount factor (gamma) or the target parameter update (tau). Increasing the number of fixed layers might help but might not\n",
    "\n",
    "#### 2) use some of the latest deep reinforcement learning improvements\n",
    "\n",
    "#####       a) Prioritized Experience Replay -- this requires rewriting the reward fuctions but seems like would help focus  the learning / training\n",
    "\n",
    "#####       b) Dueling DQN -- this allows use to assess the value of each state without having to learn the effect of each action\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
